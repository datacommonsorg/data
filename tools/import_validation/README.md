# Import Validation Framework

This document describes how to use the Import Validation Framework to run a series of automated checks on data imports.

## Overview

The framework is designed to be a flexible and extensible tool for ensuring the quality and consistency of data before it is imported. It operates on summary files generated by other import tools, such as a statistics summary and a differ output summary.

## Running the Framework

The main entry point for the framework is `runner.py`. It is a command-line tool that takes a configuration file and the paths to the summary data files as input.

### Usage

```bash
python3 -m tools.import_validation.runner \
    --validation_config=<path_to_your_config.json> \
    --stats_summary=<path_to_your_stats_summary.csv> \
    --differ_output=<path_to_your_differ_output.csv> \
    --validation_output=<path_for_your_output.csv>
```

- `--validation_config`: Path to the JSON file that defines which validations to run.
- `--stats_summary`: Path to the CSV file containing summary statistics of the import (e.g., `summary_report.csv`).
- `--differ_output`: Path to the CSV file containing the output of a differ tool (e.g., `point_analysis_summary.csv`).
- `--validation_output`: Path where the output report of the validation will be saved. The file extension (`.csv` or `.json`) determines the output format.

The script will exit with a status code of `1` if any validation fails, and `0` on success.

## Configuration

The behavior of the validation framework is controlled by a JSON configuration file. This file uses a structured schema to define a series of validation rules.

### Top-Level Structure

The configuration is a JSON object with two main sections:

- `schema_version`: The version of the configuration schema (e.g., "1.0").
- `rules`: A list of validation rule objects to be executed.

```json
{
    "schema_version": "1.0",
    "rules": [
        // Your validation rules go here
    ]
}
```

### Rule Definition

Each object in the `rules` list defines a single validation check with the following keys:

- `rule_id`: A unique, human-readable identifier for the rule.
- `validator`: The name of the validator to execute (see the table below for supported validators).
- `scope`: An object that defines the data to be validated.
- `params`: A dictionary of parameters to pass to the validator.

### Scoping and Filtering

The `scope` object specifies which data to run the validation on. It has two main parts:

- `data_source`: The key for the data source to use (`"stats"` or `"differ"`).
- `variables`: An optional filter to select a subset of StatVars from the data source.

The `variables` object can contain any of the following keys:

- `dcids`: A list of exact StatVar DCIDs to select.
- `regex`: A list of regular expressions to match against StatVar DCIDs.
- `contains_all`: A list of substrings that must all be present in the StatVar DCID.

**Note:** When multiple filter types are provided (`dcids`, `regex`, `contains_all`), the results are combined with a logical OR (union).

### Example Configuration

Here is an example of a complete configuration file:

```json
{
    "schema_version": "1.0",
    "rules": [
        {
            "rule_id": "check_latest_date_for_all",
            "validator": "MAX_DATE_LATEST",
            "scope": {
                "data_source": "stats"
            },
            "params": {}
        },
        {
            "rule_id": "check_deleted_points_threshold",
            "validator": "DELETED_COUNT",
            "scope": {
                "data_source": "differ"
            },
            "params": {
                "threshold": 10
            }
        },
        {
            "rule_id": "check_percent_max_value",
            "validator": "MAX_VALUE_CHECK",
            "scope": {
                "data_source": "stats",
                "variables": {
                    "contains_all": ["Percent"]
                }
            },
            "params": {
                "maximum": 100
            }
        }
    ]
}
```

### Advanced Validation with `SQL_VALIDATOR`

For complex validation scenarios that require aggregations, joins, or multi-column filtering, the framework provides the powerful `SQL_VALIDATOR`. This allows you to define a custom validation using a SQL query.

The validator uses two parameters:
- `query`: A standard SQL `SELECT` statement that defines the precise dataset to be validated. The `stats_summary` data is available as the `stats` table, and the `differ_output` is available as the `differ` table.
- `condition`: A SQL boolean expression that must evaluate to `TRUE` for every row returned by the `query`.

The framework executes the `query` and then finds all rows from the result that do **not** meet the `condition`. If any such rows are found, the validation fails, and the failing rows are included in the output report.

#### SQL Validator Example

**Rule:** "For all StatVars that are percentages, the `MaxValue` must be less than or equal to 100."

```json
{
    "rule_id": "check_max_value_for_percent_svs_sql",
    "validator": "SQL_VALIDATOR",
    "params": {
        "query": "SELECT StatVar, MaxValue, Units FROM stats WHERE Units = 'Percent'",
        "condition": "MaxValue <= 100"
    }
}
```

### Supported Validations

The following validations are currently supported:

| Validator Name            | Description                                                              | Required Data     | `params` Configuration                                 |
| ------------------------- | ------------------------------------------------------------------------ | ----------------- | ------------------------------------------------------ |
| `SQL_VALIDATOR`           | Runs a user-defined SQL query to perform complex validations.            | `stats`, `differ` | `query` (string), `condition` (string)                 |
| `MAX_DATE_LATEST`         | Checks that the latest date in the data is from the current year.        | `stats`           | None                                                   |
| `MAX_DATE_CONSISTENT`     | Checks that the latest date is the same for all StatVars.                | `stats`           | None                                                   |
| `DELETED_COUNT`           | Checks that the total number of deleted points is within a threshold.    | `differ`          | `threshold` (integer, defaults to 0)                   |
| `MODIFIED_COUNT`          | Checks that the number of modified points is the same for all StatVars.  | `differ`          | None                                                   |
| `ADDED_COUNT`             | Checks that the number of added points is the same for all StatVars.     | `differ`          | None                                                   |
| `NUM_PLACES_CONSISTENT`   | Checks that the number of places is the same for all StatVars.           | `stats`           | None                                                   |
| `NUM_PLACES_COUNT`        | Checks that the number of places is within a defined range.              | `stats`           | `minimum`, `maximum`, or `value` (integer)             |
| `NUM_OBSERVATIONS_CHECK`  | Checks that the number of observations is within a defined range.        | `stats`           | `minimum`, `maximum`, or `value` (integer)             |
| `UNIT_CONSISTENCY_CHECK`  | Checks that the unit is the same for all StatVars.                       | `stats`           | None                                                   |
| `MIN_VALUE_CHECK`         | Checks that the minimum value is not below a defined minimum.            | `stats`           | `minimum` (integer or float)                           |
| `MAX_VALUE_CHECK`         | Checks that the maximum value is not above a defined maximum.            | `stats`           | `maximum` (integer or float)                           |

## Output

The framework generates a report file (specified by the `--validation_output` flag) with the results of each validation. The format of the report is determined by the file extension (`.csv` or `.json`).

### CSV Output

If the output path ends with `.csv`, the file will contain the following columns:

- `ValidationName`: The unique ID of the rule that was run.
- `Status`: The result of the validation (`PASSED`, `FAILED`, `CONFIG_ERROR`, or `DATA_ERROR`).
- `Message`: A human-readable message describing the outcome.
- `Details`: A JSON string containing detailed context, especially on failures. This can include information such as the number of rows processed, succeeded, and failed.
- `ValidationParams`: A JSON string of the parameters that were passed to the validator.

### JSON Output

If the output path ends with `.json`, the file will be a JSON array where each object represents a validation result with the following keys:

- `validation_name`: The unique ID of the rule that was run.
- `status`: The result of the validation.
- `message`: A human-readable message describing the outcome.
- `details`: An object containing detailed context, including row counts.
- `validation_params`: An object containing the parameters that were passed to the validator.
